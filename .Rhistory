library(ggthemes)
library(kableExtra)
#BiocManager::install("FELLA")
library(FELLA)
library(KEGGREST)
library(igraph)
library(clusterProfiler)
library(tidyr) ## for some reason, tidyr issues are popping up so let's see what happens if we load this package last
library(stringr)
library(pathview)
library(gt) ## for pretty tables for the knit document
conflict_prefer("select", winner = "dplyr", quiet = FALSE)
conflict_prefer("filter", winner = "dplyr", quiet = FALSE)
set.seed(20150615) ## if you know why i set the seed to this date, you get a special prize
knitr::opts_chunk$set(warning = FALSE) ## just don't put in the
d1 <- read.csv("dat_file/MTBLS8183_GC-MS_positive__metabolite_profiling_v2_maf.tsv", sep = "\t") ## GCMS positive
## title: Landscape of gut microbiota and metabolites and their interaction in comorbid heart failure and depressive symptoms: a random forest analysis study 2023
#d2 <- read.csv("MTBLS8802_LC-MS_positive_hilic_metabolite_profiling_v2_maf.tsv", sep = "\t") ## LCMS positive
# our stemi paper...
#d2.5 <- read.csv("MTBLS8802_Targeted_PeakTable_all_for public upload.txt", sep = "\t")
## confirm that this is the same as d2
d3_neg <- read.csv("dat_file/compiled_stdy_metabolomics_dat - ST_001364_AN002270_neg_ion_metabolites.tsv", sep = "\t")
d3_pos <- read.csv("dat_file/compiled_stdy_metabolomics_dat - ST_001364_AN002270_pos_ion_metabolites.tsv", sep = "\t")
d2 <- read.csv("dat_file/compiled_stdy_metabolomics_dat - ST000587_AN000902_metabolites.tsv", sep = "\t")
d2_2 <- read.csv("dat_file/ST000588_1_datmat.txt", sep = "\t")
## now read in the metadata files
d1_meta <- read.csv("dat_file/MTBLS8183_sample_info.txt", sep = "\t") # feces, human
#d2_meta <- read.csv("MTBLS8802_sample_info.txt", sep = "\t")
d23_meta <- read.csv("dat_file/compiled_stdy_metabolomics_dat - metadata_st.tsv", sep = "\t")
#colnames(d2_2) %in% d23_meta$sample
#"HF08" %in% d23_meta$sample#
#length(unique(minimeta$sample))
#table(minimeta$heart_cond)
metab_desc <- read.csv("dat_file/metabolites-verlap-desc.csv")
# (!require(devtools)) install.packages("devtools")
#devtools::install_github("yanlinlin82/ggvenn")
# batch ?? transformation?
d1_metabo <- d1$metabolite_identification
d2_breath_metabo <- d2$Samples
d3n_metabo <- d3_neg$Samples ## two overlapped with d4
d3p_metabo <- d3_pos$Samples
d3_metabo <- append(d3n_metabo, d3p_metabo)
d2_2 <- d2_2 %>% filter(Metabolite_name != "Factors")
d2_2_metabo <- d2_2$Metabolite_name
#append(d2_metabo, d2_2_metabo)
## plot in a venn diagram to see the overlap simply
## reference for plotting: https://www.datanovia.com/en/blog/venn-diagram-with-r-or-rstudio-a-million-ways/
x <- list(
D1_STOOL = d1_metabo,
D2_EBC = d2_breath_metabo,
D2_SALIVA = d2_2_metabo,
D3_LV = d3_metabo)
#  D3_pos = d3p_metabo)
ggvenn(
x,
fill_color = c("#0073C2FF", "lightgoldenrod2", "lightgoldenrod3", "hotpink2"),
stroke_size = 0.5, set_name_size = 4
) +
labs(title = "Overlap of Detected Metabolites Across Studies")
ggsave("figs/supp_fig_1_venn_d123_overlap.png", height = 7, width = 7.5)
## split this to separate chunk so not included in knit doc
## just investivate what the shared metabolites are across
## the studies that qualified here
#d23_overlap <- unlist(unique(d2_metabo[d2_metabo %in% d3_metabo]))
d13_overlap <- unlist(unique(d1_metabo[d1_metabo %in% d3_metabo]))
d13_overlap <- unlist(unique(d1_metabo[d1_metabo %in% d3_metabo]))
#print("The following metabolites were detected in both left ventricle hearts and stool of HF.")
#d13_overlap
#print("The following metabolites were detected in left ventricle hearts and stool of HF PTs, negative ion")
#d13n_overlap
#print("The following metabolites were detected in breath and stool of HF PTs. ")
d12_breath_overlap <- unlist(unique(d1_metabo[d1_metabo %in% d2_breath_metabo]))
#d12_breath_overlap
#print("The following metabolites were detected in saliva and stool oh HF patients. ")
d12_sal_overlap <- unlist(unique(d1_metabo[d1_metabo %in% d2_2_metabo]))
#d12_sal_overlap
#print("The following metabolites were detected in saliva and LV. ")
d23_sal_overlap <- unlist(unique(d3_metabo[d3_metabo %in% d2_2_metabo]))
#d23_sal_overlap
#d13n_overlap
#print("The following metabolites were detected in breath and LV of HF PTs. ")
d23_breath_overlap <- unlist(unique(d3_metabo[d3_metabo %in% d2_breath_metabo]))
#d12_sal_overlap
#d23_breath_overlap
#interested_metabolites1 <- append(d23n_overlap, d13p_overlap)
interested_metabolites <- d13_overlap
d23_meta <- d23_meta %>%
mutate(heart_cond = ifelse(grepl("ICM|DCM", studyID),"HF",
ifelse(grepl("heart_failure", condition), "HF",
"CTRL"))) %>%
mutate(analysisID = ifelse(grepl("heart_failure|control", condition), "D2", "D3" ))
d1_meta <- d1_meta %>%
filter(Characteristics.Sample.type. != "pooled quality control sample") %>%
mutate(heart_cond = ifelse(grepl("HF", Factor.Value.Cohort.), "HF", "CTRL"),
sample = Source.Name)
d1_meta$studyID = "D1"
## did the above to unify HF / control labels
d1minimeta <- d1_meta %>%
select(sample, heart_cond, studyID)
d23_minimeta <- d23_meta %>% select(sample, heart_cond, studyID) %>%
mutate(studyID = ifelse(grepl("Condition", studyID), "D3",
ifelse(grepl("ST000", studyID), "D2",
"idk")))
minimeta <- base::rbind(d1minimeta, d23_minimeta)
## now combine metabilite data
d1mini  <- d1 %>% tidyr::pivot_longer(cols = QC.1:last_col(),
names_to = "sample", values_to = "abun") %>%
select(sample, metabolite_identification, abun) %>%
mutate(studyID = "D1", Samples = metabolite_identification) %>%
select(-metabolite_identification) %>%
filter(!grepl("QC", sample))
d1mini$sample <- gsub('\\.', '-', d1mini$sample)
d2mini <- d2 %>%
tidyr::pivot_longer(cols = HF01:last_col(),
names_to = "sample", values_to = "abun") %>%
mutate(studyID = "D2_EBC")
d2_2_mini <- d2_2 %>% pivot_longer(cols = C10:last_col(),
names_to = "sample", values_to = "abun") %>%
mutate(studyID = "D2_SALIVA") %>%
select(-RefMet_name)
d2_2_mini <- d2_2_mini %>%
mutate(Samples = Metabolite_name, abun = as.numeric(abun)) %>%
select(-Metabolite_name) %>%
filter(abun > 0)
d3p_mini <- d3_pos %>% pivot_longer(cols = X78_15:last_col(),
names_to = "sample", values_to = "abun") %>%
mutate(studyID = "D3")
d3n_mini <- d3_neg %>% pivot_longer(cols = X78_15:last_col(),
names_to = "sample", values_to = "abun") %>%
mutate(studyID = "D3" )
#d3_mini <- rbind(d3n_mini, d3p_mini)
d3metamin <- d23_meta %>%
filter(analysisID=="D3") %>%
select(sample,condition)
d3min <- merge(d3p_mini, d3n_mini, all = TRUE)
d3min$sample <- str_replace(d3min$sample, "X", "")
d3min <-left_join(d3min, d3metamin, join_by("sample"== "condition")) %>%
select(Samples, sample.y, studyID, abun) %>%
mutate(sample = sample.y) %>%
select(-sample.y)
#unique(d3min$studyID)
d23min <- merge(d2mini, d3min, all = TRUE)
metab1 <- merge(d1mini, d23min, all = TRUE)
metab2 <- merge(metab1, d2_2_mini, all = T) %>% filter(abun > 0)
metab <-
metab2 %>%
merge(minimeta, all = TRUE, by = "sample")%>%
mutate(studyID = paste0(studyID.x)) %>%
#filter(studyID == "D2_SALIVA") %>% ##QC check
select(-studyID.x, -studyID.y) %>%
group_by(studyID, heart_cond) %>%
mutate(tot = length(unique(sample))) %>% ## number of samples in studyID group
group_by(studyID, Samples, heart_cond) %>%
mutate(abun = as.numeric(abun))  %>% ## Samples is metabolites
mutate(grp_median = median(abun)) %>%
#dplyr::select(-studyID.x) %>%
mutate(filt_threshold = ceiling( (20*tot)/100) )  %>% ## 20 percent of samples, celing rounds up to nearest whole number
mutate(obs_count = n()) %>% ## number of obs of metabolite in samples
filter(obs_count > filt_threshold) %>% ## yay now we are filtering to remove metabolites less than 20% of sample
distinct() %>%## just a check %>%    filter(studyID == "D3")
select(-obs_count, - tot, -grp_median, -filt_threshold)
# add log transformation and median normalization
### no longer used as log transformations and median norms appear to be inappropriate for this data (data from repos is already normalized)
### however the repos don't have details on what normalization methods were used, so I just have to trust that what was uploaded is correct
## keeping this code here as a reference, also bc trans_metab df is referenced below so easier to keep this
trans_metab <-metab %>%
ungroup()
#trans_metab %>%
#  merge(metab_desc, by.x = "Samples", by.y = "Metabolite") %>%
#  filter(abun > 0) %>%
#  mutate(study_group = paste0(studyID, "_", heart_cond)) %>%
#  ggplot(aes(x = log10(abun), y = Samples, fill = study_group, shape = heart_cond)) +
#  geom_boxplot(outlier.shape = NA ) +
#  geom_point(position = position_jitterdodge(jitter.width = 0.15,
#                                             dodge.width = 1), alpha = 0.6, size = 1) +
#  theme_bw() +
#  scale_shape_manual( values=c("HF"=15, "CTRL" = 17, "NA" = 10) ) +
#  scale_fill_manual(values = r_pal) +
#  facet_wrap(.~fxnl_category, scales = "free")
## this function name is a bit misleading - "raw_abun" refers to raw value from the repo, not a raw value from metabolomics machines.
## however I'm not changing it because 1) im afraid of breaking something and 2) this is a relic of when we were trying to figure out what normalization methods had been applied to the data in the repos
## I was able to replicate the PCAs in the pubs with this method
conduct_pca_raw_abun <- function(studyID_filt, main_dat){
d1wide <- main_dat %>%
ungroup() %>%
select(Samples, abun, sample, studyID)%>%
filter(studyID == studyID_filt)%>%
#    mutate(norm_abun_log10 = as.numeric(.data$norm_abun_log10)) %>%
pivot_wider(names_from = "Samples", values_from = abun, values_fill = 0 )
# return(d1wide)
d1_pca <- main_dat %>%
ungroup() %>%
select(Samples, abun, sample, studyID)%>%
filter(studyID == studyID_filt)%>%
pivot_wider(names_from = "Samples", values_from = abun, values_fill = 0 ) %>%
select(where(is.numeric)) %>% # retain only numeric columns
prcomp(scale = TRUE) # do PCA on scaled data
d1wide <- merge(d1wide, minimeta, by = "sample", all.x = T) %>% distinct()
d1wide <- d1wide %>% mutate(study_group = paste0(studyID.x, "_",heart_cond))
plot_name <- paste0(studyID_filt, " PCA Plot")
pca_plot <- d1_pca %>%
augment(d1wide) %>% # add original dataset back in
ggplot(aes(.fittedPC1, .fittedPC2, color = heart_cond)) +
geom_point(size = 3, alpha = 0.7) +
scale_color_manual(values = c(HF = "goldenrod3", CTRL = "grey45")  ) +
theme_hc(12) + background_grid() +
labs(title = plot_name, x = "PC1", y = "PC2" ) +
stat_ellipse() +
theme(legend.title = element_blank())
## again, leaving this here if other people want to test it out with this data
#arrow_style <- arrow(    angle = 20, ends = "first", type = "closed", length = grid::unit(8, "pt"))
# plot rotation matrix
#arrow_plot <- d1_pca %>%
#  tidy(matrix = "rotation") %>%
#  pivot_wider(names_from = "PC", names_prefix = "PC", values_from = "value") %>%
#  ggplot(aes(PC1, PC2)) +
#  geom_segment(xend = 0, yend = 0, arrow = arrow_style) +
#  geom_text(
#    aes(label = column),
#    hjust = 1, nudge_x = -0.02,
#    color = "#904C2F"
#  ) +
#xlim(-1.25, .5) + ylim(-.5, 1) +
#  coord_fixed() + # fix aspect ratio to 1:1
# theme_minimal_grid(12) + labs(title = plot_name)
#percent_plot <- d1_pca %>%
#  tidy(matrix = "eigenvalues") %>%
#  ggplot(aes(as.integer(PC), percent)) +
#  geom_col(fill = "#56B4E9", alpha = 0.8) +
#  scale_y_continuous(
#    labels = scales::percent_format(),
#    expand = expansion(mult = c(0, 0.01))
#  ) +
#  theme_hc(12) +
#  labs(title = "% Var.", y = "Percent Variance Explained", x = "PC") +
#xlim(0,10) # ylim(0,10) +
#  scale_x_continuous(limits = c(0, 11), breaks = c(0, 2, 4, 6, 8, 10))
#combo_plot <- plot_grid(pca_plot, percent_plot, rel_widths = c(2, 1))
#return(pca_plot)
#return(arrow_plot)
#return(percent_plot)
return(pca_plot)
}
p3 <- conduct_pca_raw_abun("D3", main_dat=trans_metab)
ggsave("figs/pca_wo_pv_d3.png", height = 7, width = 10)
p1 <- conduct_pca_raw_abun("D1", main_dat=trans_metab)
ggsave("figs/pca_wo_pv_d1.png", height = 7, width = 10)
#ggsave("d1_raw_abun.png")
p2_ebc <- conduct_pca_raw_abun("D2_EBC", main_dat=trans_metab)
ggsave("figs/pca_wo_pv_d2_ebc.png", height = 7, width = 10)
p2_sal <- conduct_pca_raw_abun("D2_SALIVA", main_dat=trans_metab)
ggsave("figs/pca_wo_pv_d2_saliva.png", height = 7, width = 10)
pca_all <- plot_grid(p1,p3, p2_ebc, p2_sal, ncol = 2, labels = "AUTO", byrow = TRUE)
pca_all
ggsave("figs/pca_wo_pv_all.png", dpi = 400, height = 10, width = 10)
univariate_testing <- function(studyID_filt, main_dat){
y = data.frame("pval", "metabolite", "studyID", "adj_pval_fdr")
colnames(y) <- c("pval", "metabolite", "studyID", "adj_pval_fdr")
smol_dat <- main_dat %>%
ungroup() %>%
filter(studyID == studyID_filt)
metab_list <- as.list(unique(smol_dat$Samples))
for (i in metab_list) {
new_line = data.frame("pval", "metabolite", "studyID", "adj_pval_fdr")
univar_testing <- smol_dat %>%
filter(Samples == i ) %>%
distinct() %>%
mutate(heart_cond = as.factor(heart_cond)) #%>%filter(length( forcats::fct_unique(heart_cond)) == 2)
## something to confirm two levels of factor
if (length( forcats::fct_unique(univar_testing$heart_cond)) == 2) {
x_abun <- univar_testing$abun
y_heart_cond <- univar_testing$heart_cond
w <- wilcox.test(x_abun ~ y_heart_cond, alternative = "two.sided", exact = TRUE)
new_line$pval <- as.numeric(w$p.value)
new_line$metabolite <- i
new_line$studyID <- studyID_filt
new_line <- new_line %>% select(pval, metabolite, studyID) %>%
mutate(adj_pval_fdr = p.adjust(pval, method = "fdr", n = length(metab_list)))
y <- rbind(y, new_line)
}
}
## after math add info to file
fname = paste0("dat_file/univariate_testing_", studyID_filt, ".txt")
write.table(y, file = fname, append = FALSE, quote = FALSE, row.names = FALSE, sep = "\t")
}
univariate_testing("D2_SALIVA", trans_metab)
univariate_testing("D2_EBC", trans_metab)
univariate_testing("D3", trans_metab)
univariate_testing("D1", trans_metab)
make_volc_plots <- function(studyID_filt, main_dat){
fname = paste0("dat_file/univariate_testing_", studyID_filt, ".txt")
d <- read.csv(file =fname, sep = "\t", skip = 1, row.names = NULL)
d_sig <- d %>% filter(adj_pval_fdr < 0.05)
sig_metas <- main_dat %>%
filter(studyID ==  studyID_filt) %>%
filter(Samples %in% d_sig$metabolite) %>%
ggplot(aes(x = heart_cond, y = abun, fill = heart_cond)) +
geom_boxplot(outlier.shape = NA, alpha = 0.5) +
geom_jitter(height = 0, width = 0.2, alpha = 0.7) +
theme_bw() +
scale_fill_manual(values = cbbPalette) +
facet_wrap(.~Samples, scales = "free") +
labs(title = paste0("Significant Metabolites, ", studyID_filt)) +
theme_set(theme_bw(base_size=20))
plotname = paste0("significant_metabolites_", studyID_filt, ".png")
ggsave(plotname, height = 15, width = 20, plot = sig_metas)
#volcano plot??
volc_plot <- main_dat %>%
filter(studyID == studyID_filt) %>%
#ungroup() %>%
group_by(heart_cond, Samples) %>%
summarise(value = median(abun) ) %>%
pivot_wider(names_from = heart_cond, values_from = value, values_fill = 0.000001) %>%
mutate(fold_change = log2(HF) - log2(CTRL)) %>%
mutate(label_info = ifelse(fold_change %in% top_n(x = ., n = 10, wt = fold_change), "top10", " ")) %>%
merge(d, by.x = "Samples", by.y = "metabolite") %>%
mutate(signi = ifelse(Samples %in% d_sig$metabolite, "significant", "not significant"))%>%
ggplot(aes(x = fold_change, y = -log10(adj_pval_fdr), color = signi)) +
scale_color_manual(values = cbbPalette) +
labs(title = paste0(studyID_filt," Volcano Plot"), color = " ") +
theme_pubclean()  +
geom_vline(xintercept=c(0), linetype = "dashed") +
geom_hline(yintercept=-log10(0.05), linetype = "dashed") +
#geom_text(aes(label=ifelse(label_info=="top10",as.character(Samples),'')),hjust=0,vjust=0)
geom_label_repel(aes(label = Samples),
box.padding   = 0.35,
point.padding = 0.5,
segment.color = 'grey50',
max.overlaps = 15) +
theme_set(theme_pubclean(base_size=20))+
geom_point()# +
#scale_x_continuous(expand = expansion(add = 0.5)) +
#scale_y_continuous(expand = expansion(add = c(0,3)))
print(volc_plot)
plot2name = paste0("volcanoplot_", studyID_filt, ".png")
ggsave(plot2name, plot = volc_plot)
#print(d_sig)
#print(volc_plot)
}
v1 <- make_volc_plots("D1", trans_metab)
ggsave("figs/volcano_plt_d1.png", dpi = 300)
v3 <- make_volc_plots("D3", trans_metab)
ggsave("figs/volcano_plt_d3.png", dpi = 300)
## d2 studies have no sig after adjustment so not running
set.seed(20150615) ## if you know why i set the seed to this date, you get a special prize##
## this is repeated from the set up just to be sure that the seed is right
minimeta <- rbind(minimeta,
minimeta %>%
filter(studyID == "D2") %>%
mutate(studyID = "D2_SALIVA"))
conduct_oplsda <- function(studyID_filt, main_dat){
metab_wide <- main_dat %>%
ungroup() %>%
pivot_wider(names_from = Samples, values_from = abun, values_fill = 0)
inMeta <- minimeta %>% filter(studyID == studyID_filt & sample %in% metab_wide$sample) %>% arrange(sample) %>% select(-studyID)
colnames(inMeta) <- c("ind", "group")
## prep dataframe
inData <-
metab %>% ungroup() %>% filter(studyID == studyID_filt) %>%
dplyr::select(Samples, abun, sample, studyID) %>%
distinct() %>%
filter(sample %in% inMeta$ind) %>%
#  group_by(sample, Samples) %>%
#    filter(n()>1)
mutate(sample = paste0(sample, "_", studyID)) %>%
pivot_wider(names_from = "Samples", values_from = "abun") %>%
ungroup() %>%
dplyr::select(-studyID, -sample) #%>%  arrange(sample)
opls.pca <- opls(inData)
vect_y <- inMeta$group
fname = paste0("figs/oplsda_model_", studyID_filt, ".svg")
hf.oplsda <- opls(inData, vect_y, predI = 1, orthoI = NA, subset = "odd", plotSubC = studyID_filt)
ggsave(fname)
hf.oplsda <- opls(inData, vect_y, predI = 1, orthoI = NA, plotSubC = studyID_filt)
plot(hf.oplsda,
typeVc = "x-score",
parAsColFcVn = vect_y,
fig = fname, plotSubC = studyID_filt,
parPaletteVc = c("grey30", "goldenrod2"))
}
## prep inMeta for RDS
conduct_oplsda("D3", trans_metab)
conduct_oplsda("D1", trans_metab)
cats <- read.csv("dat_file/sig_metabolites_univariate_analysis_fdr - Sheet1.csv")
## merge categories for abundances for some plotting
unidat <- metab %>%
select(sample, Samples, abun, studyID, heart_cond) %>%
merge(cats, metab, by.y = "metabolite", by.x = "Samples") %>%
filter(!grepl("QC", sample)) %>%
mutate(study_group = as.factor(paste0(studyID.y, "_", heart_cond)))
unidat$studyID = unidat$studyID.x
unidat <- unidat %>% select(-studyID.x, -studyID.y) %>% mutate(adj.p = ifelse(adj_pval_fdr >= 0.001, paste0("= ", adj_pval_fdr), "< 0.001"))
for (i in unique(unidat$Samples)) {
textdat <- unidat %>%
filter(Samples == i) %>%
select(adj.p, study_group)
a <- unidat %>%
filter(Samples == i) %>%
ggplot(aes(x = Samples, y = abun, fill = study_group)) +
geom_boxplot(outlier.shape = NA, alpha = 0.5) +
geom_point(position = position_jitterdodge(), alpha = 0.7)+
theme_bw() +
facet_wrap(.~pathway, scales = "free") +
labs(title = paste0(i), x = "") +
theme_set(theme_bw(base_size=10))+
scale_fill_manual(values = c("D1_CTRL" = "grey30",
"D3_CTRL" = "grey20",
"D1_HF" = "goldenrod3",
"D3_HF" = "goldenrod1")) +
#geom_text(data = textdat, aes(x = 1.5, y = 0, label = paste0("adj. p ", adj.p)))
labs(subtitle = paste0("adj. p ", textdat$adj.p), size = 5) +
theme(legend.position = "top", legend.title = element_blank())
print(a)
fname = paste0("univariate_sig_plots/",i, ".png" )
ggsave(plot=a, filename=fname, dpi = 300, height = 4, width = 3)
}
#library(pathview)
kegg <- read.csv("dat_file/map_common_name_to_kegg.csv.csv")
pathdat <- merge(unidat, kegg, by.x = "Samples", by.y = "Query", all.x = TRUE)
#pathdat %>%
#  filter(adj_pval_fdr < 0.05) %>%
#  select(sample,heart_cond, Samples, abun, KEGG)
graph <- buildGraphFromKEGGREST( organism = "hsa", filter.path = NULL) ## only needs to run once per session for users
tmpdir <- paste0(tempdir(), "\\my_database2")
# Make sure the database does not exist from a former vignette build
# Otherwise the vignette will rise an error
# because FELLA will not overwrite an existing database
unlink(tmpdir, recursive = TRUE)
buildDataFromGraph(keggdata.graph = graph,
databaseDir = tmpdir,
internalDir = FALSE,
matrices = "none",
normality = "diffusion",
niter = 100)
fella.data <- loadKEGGdata(databaseDir = tmpdir,
internalDir = FALSE,
loadMatrix = "none")
pathdat %>%
group_by(studyID) %>%
summarize(unique_kegg = length(unique(KEGG)))
## not many things mapping to kegg pathways so different pathway analysis below
cur_path <- getwd()
pathway_analysis <- function(studyID_filt, main_dat, filt_cat){
filt_dat <- main_dat %>% filter(studyID == studyID_filt)
cmp.list <- filt_dat$KEGG
analysis.enrich <- enrich(compounds = cmp.list,
data = fella.data,
method = "diffusion",
approx = "simulation")
analysis.enrich %>%
getInput() %>%
getName(data = fella.data)
plot(analysis.enrich,
method = "diffusion",
data = fella.data,
nlimit = 250,
plotLegend = FALSE)
## subnetwork analysis
#  g.enrich <- generateResultsGraph(object = analysis.enrich,
#                              data = fella.data,  method = "diffusion")
#  tab.enrich <- generateResultsTable(object = analysis.enrich,
#                                  data = fella.data,
#                                  method = "diffusion")
plot(analysis.enrich,
method = "diffusion",
data = fella.data,
nlimit = 50,
plotLegend = TRUE,)
myTable <- generateResultsTable(
object = analysis.enrich,
method = "diffusion",
#threshold = 0.05, ## p thresh?
data = fella.data)
#print(knitr::kable(head(myTable, 20))) ## print top 20 table, depreciated since written to file now
k_name = paste0("dat_file/kable_tbl_", studyID_filt)
myTable$studyID = studyID_filt
write.csv(myTable, file = k_name, row.names = TRUE, quote = FALSE)
plot(
x = analysis.enrich,
method = "diffusion",
main = "Enrichment using the diffusion analysis in FELLA",
threshold = 0.01,
data = fella.data
)
## write a lil something something to automatically visualize the top 10 pathways per study here
top10 <- myTable$KEGG.id[1:10]
setwd(paste0(cur_path, "/dat_file/"))
for ( i in top10){
i = as.character(i)
fname = paste0(studyID_filt, "_", i)
pathview(cpd.data = cmp.list, species = "hsa", pathway.id = i, out.suffix = fname, kegg.native = FALSE)
}
}
pathway_analysis("D1", pathdat) ## take a huge amount of processing so leaving out
setwd(cur_path)
pathway_analysis("D3", pathdat)
setwd(cur_path)
pathdat <- pathdat %>%
mutate(db_id = ifelse(!is.na(HMDB), paste0("hmdb:", HMDB),  paste0("pubchem:", PubChem)))
#                       ifelse(!is.na(ChEBI), paste0("chebi:", ChEBI),
#                              ifelse(!is.na(KEGG), paste0("kegg:",KEGG), Samples
#                                     ))))) %>%
pathdat %>%
select(db_id) %>%
distinct() %>%
write_csv(file = "dat_file/data_full_annotation.csv")
install.packages(“tinytex”)
install.packages(“tinytex”)
install.packages("tinytex")
#install.packages("tinytex")
library(tinytex)
install.packages("mitktex")
